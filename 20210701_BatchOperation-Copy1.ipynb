{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hazardous-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import statistics\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "from pandas import Series\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import seaborn as sns\n",
    "import os\n",
    "import statistics\n",
    "\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from dateutil.relativedelta import relativedelta \n",
    "from scipy.optimize import minimize              \n",
    "\n",
    "import statsmodels.formula.api as smf          \n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as scs\n",
    "\n",
    "from itertools import product      \n",
    "\n",
    "from statsmodels.tsa.api import ExponentialSmoothing,SimpleExpSmoothing, Holt\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "random-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    squared_error = 0\n",
    "    for i in range(len(y_true)):\n",
    "        squared_error = squared_error + (y_true[i] - y_pred[i]) ** 2\n",
    "    root_mean_squared_error = sqrt(squared_error / len(y_true))\n",
    "    return root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "freelance-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_avg(rounds):\n",
    "    y_hat['avg'] = 0\n",
    "    for i in range(len(Valid)):\n",
    "        y_pred = 0\n",
    "        for j in range(rounds):\n",
    "            y_pred = y_pred + Train.footfall[len(Train) - (j + 1) * len(Valid) + i]\n",
    "        y_hat['avg'][i] = y_pred / rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "graphic-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationary(timeseries):\n",
    "    #Determine rolling statistics\n",
    "    rolmean = pd.Series(timeseries).rolling(window = 28).mean()\n",
    "    rolstd = pd.Series(timeseries).rolling(window = 28).std()\n",
    "    \n",
    "    #Plot rolling Statistics\n",
    "    orig = plt.plot(timeseries, color = \"blue\", label = \"Original\")\n",
    "    mean = plt.plot(rolmean, color = \"red\", label = \"Rolling Mean\")\n",
    "    std = plt.plot(rolstd, color = \"black\", label = \"Rolling Std\")\n",
    "    plt.legend(loc = \"best\")\n",
    "    plt.title(\"Rolling Mean and Standard Deviation\")\n",
    "    plt.show(block = False)\n",
    "    \n",
    "    #Perform Dickey Fuller test\n",
    "    print(\"Results of Dickey Fuller test: \")\n",
    "    dftest = adfuller(timeseries, autolag = 'AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index = ['Test Statistics', 'p-value', '# Lag Used', 'Number of Observations Used'])\n",
    "    \n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)' %key] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-financing",
   "metadata": {},
   "source": [
    "### Exclude Locations with Too Much Missing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "authentic-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = pd.read_csv('stackfootfall.csv')\n",
    "ff.timestamp = pd.to_datetime(ff.timestamp, format = '%Y-%m-%d %H:%M:%S') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "white-passion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>location</th>\n",
       "      <th>device</th>\n",
       "      <th>footfall</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>footfall_x</th>\n",
       "      <th>footfall_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1344</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.892256</td>\n",
       "      <td>0.833766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1345</td>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>899.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.892256</td>\n",
       "      <td>0.833766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1346</td>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.892256</td>\n",
       "      <td>0.833766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1347</td>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.892256</td>\n",
       "      <td>0.833766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1348</td>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1780.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.892256</td>\n",
       "      <td>0.833766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002195</th>\n",
       "      <td>233635</td>\n",
       "      <td>2019-08-18 19:00:00</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>0.619529</td>\n",
       "      <td>0.955844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002196</th>\n",
       "      <td>233636</td>\n",
       "      <td>2019-08-18 20:00:00</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>0.619529</td>\n",
       "      <td>0.955844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002197</th>\n",
       "      <td>233637</td>\n",
       "      <td>2019-08-18 21:00:00</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>0.619529</td>\n",
       "      <td>0.955844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002198</th>\n",
       "      <td>233638</td>\n",
       "      <td>2019-08-18 22:00:00</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>0.619529</td>\n",
       "      <td>0.955844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002199</th>\n",
       "      <td>233639</td>\n",
       "      <td>2019-08-18 23:00:00</td>\n",
       "      <td>1168.0</td>\n",
       "      <td>827.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>0.619529</td>\n",
       "      <td>0.955844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5002200 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0           timestamp  location  device  footfall  year  \\\n",
       "0              1344 2018-01-01 00:00:00       5.0  1780.0     494.0  2018   \n",
       "1              1345 2018-01-01 01:00:00       5.0  1780.0     899.0  2018   \n",
       "2              1346 2018-01-01 02:00:00       5.0  1780.0     770.0  2018   \n",
       "3              1347 2018-01-01 03:00:00       5.0  1780.0     599.0  2018   \n",
       "4              1348 2018-01-01 04:00:00       5.0  1780.0     331.0  2018   \n",
       "...             ...                 ...       ...     ...       ...   ...   \n",
       "5002195      233635 2019-08-18 19:00:00    1168.0   827.0      42.0  2019   \n",
       "5002196      233636 2019-08-18 20:00:00    1168.0   827.0      10.0  2019   \n",
       "5002197      233637 2019-08-18 21:00:00    1168.0   827.0      13.0  2019   \n",
       "5002198      233638 2019-08-18 22:00:00    1168.0   827.0       1.0  2019   \n",
       "5002199      233639 2019-08-18 23:00:00    1168.0   827.0       6.0  2019   \n",
       "\n",
       "         month  day  hour  day_of_week  footfall_x  footfall_y  \n",
       "0            1    1     0            1    0.892256    0.833766  \n",
       "1            1    1     1            1    0.892256    0.833766  \n",
       "2            1    1     2            1    0.892256    0.833766  \n",
       "3            1    1     3            1    0.892256    0.833766  \n",
       "4            1    1     4            1    0.892256    0.833766  \n",
       "...        ...  ...   ...          ...         ...         ...  \n",
       "5002195      8   18    19            7    0.619529    0.955844  \n",
       "5002196      8   18    20            7    0.619529    0.955844  \n",
       "5002197      8   18    21            7    0.619529    0.955844  \n",
       "5002198      8   18    22            7    0.619529    0.955844  \n",
       "5002199      8   18    23            7    0.619529    0.955844  \n",
       "\n",
       "[5002200 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff = ff.loc[(ff.timestamp >= '2018-01') & (ff.timestamp <= '2019-08-18 23:00')]\n",
    "\n",
    "ff_count = ff.groupby('location')['footfall'].count() / max(ff.groupby('location')['footfall'].count())\n",
    "limit1 = ff_count.loc[ff_count >= 0.6].to_frame()\n",
    "ff_test = ff.loc[(ff.timestamp >= '2018-07-29') & (ff.timestamp <= '2019-08-18 23:00')]\n",
    "ff_test_count = ff_test.groupby('location')['footfall'].count() / max(ff_test.groupby('location')['footfall'].count())\n",
    "limit2 = ff_test_count.loc[ff_test_count >= 0.8].to_frame()\n",
    "limit = pd.merge(limit1, limit2, how = 'inner', on = 'location')\n",
    "\n",
    "ff = pd.merge(ff, limit, how = 'inner', on = 'location')\n",
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "appropriate-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns = ('location','Naive','Moving_Average12','Moving_Average24',\n",
    "                                 'Moving_Average30','Expoential_Smoothing','SARIMA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "confirmed-pantyhose",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\urbsim\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "E:\\Anaconda3\\envs\\urbsim\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "E:\\Anaconda3\\envs\\urbsim\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "E:\\Anaconda3\\envs\\urbsim\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "E:\\Anaconda3\\envs\\urbsim\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "E:\\Anaconda3\\envs\\urbsim\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "E:\\Anaconda3\\envs\\urbsim\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "E:\\Anaconda3\\envs\\urbsim\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "E:\\Anaconda3\\envs\\urbsim\\lib\\site-packages\\statsmodels\\base\\model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for loc in ff.location.unique()[0:10]:\n",
    "\n",
    "    ff_loc = ff.loc[(ff.location <= loc) & (ff.location >= loc)][[\n",
    "        'timestamp','footfall','year','month','day','hour','day_of_week']]    \n",
    "    ff_loc.index = ff_loc.timestamp\n",
    "    ff_loc = ff_loc.resample('H').mean()\n",
    "\n",
    "    ff_loc['footfall'].replace(0, np.nan, inplace = True)\n",
    "    ff_loc['footfall'] = ff_loc['footfall'].inter         polate(method='linear')\n",
    "    ff_loc = ff_loc.reset_index(level = ['timestamp'])\n",
    "    ff_loc.timestamp = pd.to_datetime(ff_loc.timestamp, format = '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    temp = ff_loc[['timestamp', 'footfall']]\n",
    "    temp.index = temp.timestamp\n",
    "    temp['year'] = temp.timestamp.dt.year\n",
    "    temp['month'] = temp.timestamp.dt.month\n",
    "    temp['day'] = temp.timestamp.dt.day\n",
    "    temp['hour'] = temp.timestamp.dt.hour\n",
    "    temp['day_of_week'] = temp.timestamp.dt.dayofweek + 1\n",
    "\n",
    "    Train = temp.loc[(temp.timestamp >= '2018-01-01 00:00') & (temp.timestamp <= '2019-07-28 23:00')]\n",
    "    Valid = temp.loc[(temp.timestamp >= '2019-07-29 00:00') & (temp.timestamp <= '2019-08-18 23:00')]\n",
    "\n",
    "    train = Train.resample('D').mean()\n",
    "    valid = Valid.resample('D').mean() \n",
    "\n",
    "    train['footfall'] = train['footfall'].interpolate(method='linear')\n",
    "    valid['footfall'] = valid['footfall'].interpolate(method='linear')\n",
    "\n",
    "    # Monday to Thursday Ratio\n",
    "    mtt = Train.loc[(Train.day_of_week >= 1) & (Train.day_of_week <= 4)].groupby('hour')['footfall'].mean().to_frame()\n",
    "    mtt['ratio'] = mtt['footfall']/mtt['footfall'].sum()\n",
    "    mtt = mtt.reset_index(level = ['hour'])\n",
    "\n",
    "    # Friday Ratio\n",
    "    fri = Train.loc[(Train.day_of_week >= 5) & (Train.day_of_week <= 5)].groupby('hour')['footfall'].mean().to_frame()\n",
    "    fri['ratio'] = fri['footfall']/fri['footfall'].sum()\n",
    "    fri = fri.reset_index(level = ['hour'])\n",
    "\n",
    "    # Sat Ratio\n",
    "    sat = Train.loc[(Train.day_of_week >= 6) & (Train.day_of_week <= 6)].groupby('hour')['footfall'].mean().to_frame()\n",
    "    sat['ratio'] = sat['footfall']/sat['footfall'].sum()\n",
    "    sat = sat.reset_index(level = ['hour'])\n",
    "\n",
    "    # Sun Ratio\n",
    "    sun = Train.loc[(Train.day_of_week >= 7) & (Train.day_of_week <= 7)].groupby('hour')['footfall'].mean().to_frame()\n",
    "    sun['ratio'] = sun['footfall']/sun['footfall'].sum()\n",
    "    sun = sun.reset_index(level = ['hour'])\n",
    "\n",
    "    ratio1 = mtt[['hour','ratio']]\n",
    "    ratio1['day_of_week'] = 1\n",
    "    ratio2 = mtt[['hour','ratio']]\n",
    "    ratio2['day_of_week'] = 2\n",
    "    ratio3 = mtt[['hour','ratio']]\n",
    "    ratio3['day_of_week'] = 3\n",
    "    ratio4 = mtt[['hour','ratio']]\n",
    "    ratio4['day_of_week'] = 4\n",
    "    ratio5 = fri[['hour','ratio']]\n",
    "    ratio5['day_of_week'] = 5\n",
    "    ratio6 = sat[['hour','ratio']]\n",
    "    ratio6['day_of_week'] = 6\n",
    "    ratio7 = sun[['hour','ratio']]\n",
    "    ratio7['day_of_week'] = 7\n",
    "\n",
    "    ratio_week = ratio1.append(ratio2).append(ratio3).append(ratio4).append(ratio5).append(ratio6).append(ratio7)\n",
    "\n",
    "    merge = pd.merge(Valid, ratio_week, on = ('hour','day_of_week'), how = 'left')\n",
    "\n",
    "    # Naive Approach\n",
    "    dd = np.asarray(Train['footfall'])\n",
    "    y_hat = Valid.copy()\n",
    "    y_hat['naive']= dd[len(dd)- 1]\n",
    "    for i in range(len(Valid)): \n",
    "        y_hat['naive'][i]= dd[len(dd) - len(Valid) + i]\n",
    "    naive_rmse = rmse(Valid.footfall, y_hat.naive)\n",
    "\n",
    "    # Moving Average Approach\n",
    "    moving_avg(4)\n",
    "    avg4_rmse = rmse(Valid.footfall, y_hat.avg)\n",
    "    moving_avg(8)\n",
    "    avg8_rmse = rmse(Valid.footfall, y_hat.avg)\n",
    "    moving_avg(10)\n",
    "    avg10_rmse = rmse(Valid.footfall, y_hat.avg)\n",
    "\n",
    "    # Exponential Smoothing\n",
    "    y_hat = valid.copy()\n",
    "    fit1 = ExponentialSmoothing(np.asarray(train.footfall), seasonal_periods = 7, trend = 'add', seasonal= 'add').fit()\n",
    "    y_hat['Holt_Winter'] = fit1.forecast(len(valid))    \n",
    "    HoltWinter_rmse = rmse(valid.footfall, y_hat.Holt_Winter)\n",
    "\n",
    "    pred_d = y_hat.Holt_Winter.to_frame()\n",
    "    pred_d = pred_d.reset_index(level = ['timestamp'])\n",
    "    pred_d['month'] = pred_d.timestamp.dt.month\n",
    "    pred_d['day'] = pred_d.timestamp.dt.day\n",
    "    temp = pd.merge(merge, pred_d, on = ('month','day'), how = 'left')\n",
    "    temp['prediction'] = temp['ratio'] * temp['Holt_Winter'] * 24\n",
    "    holt_winter_rmse = rmse(temp['footfall'], temp['prediction'])\n",
    "\n",
    "    # SARIMA\n",
    "    fit1 = sm.tsa.statespace.SARIMAX(train.footfall, order = (1,1,3), seasonal_order =(1,1,3,7)).fit()\n",
    "    y_hat['SARIMA'] = fit1.predict(start = \"2019-07-29 00:00\", end = \"2019-08-18 23:00\", dynamic=True)\n",
    "    SARIMA_rmse = rmse(valid['footfall'], y_hat['SARIMA'])\n",
    "\n",
    "    pred_d = y_hat['SARIMA'].to_frame()\n",
    "    pred_d = pred_d.reset_index(level = ['timestamp'])\n",
    "    pred_d['month'] = pred_d.timestamp.dt.month\n",
    "    pred_d['day'] = pred_d.timestamp.dt.day\n",
    "    temp2 = pd.merge(merge, pred_d, on = ('month','day'), how = 'left')\n",
    "    temp2['prediction'] = temp2['ratio'] * temp2['SARIMA'] * 24\n",
    "    sarima_rmse = rmse(temp2['footfall'], temp2['prediction'])\n",
    "\n",
    "    result = result.append({'location': loc, 'Naive': naive_rmse, 'Moving_Average12': avg4_rmse, 'Moving_Average24': avg8_rmse, \n",
    "                           'Moving_Average30': avg10_rmse, 'Expoential_Smoothing': holt_winter_rmse, 'SARIMA': sarima_rmse},\n",
    "                           ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "damaged-salad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>Naive</th>\n",
       "      <th>Moving_Average12</th>\n",
       "      <th>Moving_Average24</th>\n",
       "      <th>Moving_Average30</th>\n",
       "      <th>Expoential_Smoothing</th>\n",
       "      <th>SARIMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>660.733618</td>\n",
       "      <td>438.124377</td>\n",
       "      <td>380.697612</td>\n",
       "      <td>435.824077</td>\n",
       "      <td>423.488557</td>\n",
       "      <td>417.842803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>520.571453</td>\n",
       "      <td>450.796608</td>\n",
       "      <td>327.748727</td>\n",
       "      <td>371.546914</td>\n",
       "      <td>396.486996</td>\n",
       "      <td>350.549984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>277.951764</td>\n",
       "      <td>216.414675</td>\n",
       "      <td>190.836343</td>\n",
       "      <td>208.629228</td>\n",
       "      <td>209.257630</td>\n",
       "      <td>208.223988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>511.515018</td>\n",
       "      <td>377.816876</td>\n",
       "      <td>392.249377</td>\n",
       "      <td>440.817514</td>\n",
       "      <td>328.671785</td>\n",
       "      <td>315.860758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.0</td>\n",
       "      <td>321.298819</td>\n",
       "      <td>226.211294</td>\n",
       "      <td>214.664716</td>\n",
       "      <td>248.059289</td>\n",
       "      <td>245.561794</td>\n",
       "      <td>233.264410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>78.0</td>\n",
       "      <td>686.925250</td>\n",
       "      <td>488.953839</td>\n",
       "      <td>378.221677</td>\n",
       "      <td>440.177805</td>\n",
       "      <td>416.956271</td>\n",
       "      <td>425.775341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>87.0</td>\n",
       "      <td>280.699218</td>\n",
       "      <td>222.816230</td>\n",
       "      <td>208.413313</td>\n",
       "      <td>209.433377</td>\n",
       "      <td>193.382826</td>\n",
       "      <td>198.950650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>88.0</td>\n",
       "      <td>181.602965</td>\n",
       "      <td>175.427137</td>\n",
       "      <td>143.093646</td>\n",
       "      <td>142.725657</td>\n",
       "      <td>177.919970</td>\n",
       "      <td>155.171088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>89.0</td>\n",
       "      <td>170.063667</td>\n",
       "      <td>225.046256</td>\n",
       "      <td>204.175617</td>\n",
       "      <td>211.756172</td>\n",
       "      <td>207.826243</td>\n",
       "      <td>205.387776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>91.0</td>\n",
       "      <td>202.499036</td>\n",
       "      <td>159.444603</td>\n",
       "      <td>139.627218</td>\n",
       "      <td>143.965067</td>\n",
       "      <td>179.807262</td>\n",
       "      <td>142.644924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location       Naive  Moving_Average12  Moving_Average24  Moving_Average30  \\\n",
       "0       5.0  660.733618        438.124377        380.697612        435.824077   \n",
       "1       6.0  520.571453        450.796608        327.748727        371.546914   \n",
       "2       7.0  277.951764        216.414675        190.836343        208.629228   \n",
       "3      31.0  511.515018        377.816876        392.249377        440.817514   \n",
       "4      62.0  321.298819        226.211294        214.664716        248.059289   \n",
       "5      78.0  686.925250        488.953839        378.221677        440.177805   \n",
       "6      87.0  280.699218        222.816230        208.413313        209.433377   \n",
       "7      88.0  181.602965        175.427137        143.093646        142.725657   \n",
       "8      89.0  170.063667        225.046256        204.175617        211.756172   \n",
       "9      91.0  202.499036        159.444603        139.627218        143.965067   \n",
       "\n",
       "   Expoential_Smoothing      SARIMA  \n",
       "0            423.488557  417.842803  \n",
       "1            396.486996  350.549984  \n",
       "2            209.257630  208.223988  \n",
       "3            328.671785  315.860758  \n",
       "4            245.561794  233.264410  \n",
       "5            416.956271  425.775341  \n",
       "6            193.382826  198.950650  \n",
       "7            177.919970  155.171088  \n",
       "8            207.826243  205.387776  \n",
       "9            179.807262  142.644924  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "outer-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dm_test(actual_lst, pred1_lst, pred2_lst, h = 1, crit=\"MSE\", power = 2):\n",
    "    # Routine for checking errors\n",
    "    def error_check():\n",
    "        rt = 0\n",
    "        msg = \"\"\n",
    "        # Check if h is an integer\n",
    "        if (not isinstance(h, int)):\n",
    "            rt = -1\n",
    "            msg = \"The type of the number of steps ahead (h) is not an integer.\"\n",
    "            return (rt,msg)\n",
    "        # Check the range of h\n",
    "        if (h < 1):\n",
    "            rt = -1\n",
    "            msg = \"The number of steps ahead (h) is not large enough.\"\n",
    "            return (rt,msg)\n",
    "        len_act = len(actual_lst)\n",
    "        len_p1  = len(pred1_lst)\n",
    "        len_p2  = len(pred2_lst)\n",
    "        # Check if lengths of actual values and predicted values are equal\n",
    "        if (len_act != len_p1 or len_p1 != len_p2 or len_act != len_p2):\n",
    "            rt = -1\n",
    "            msg = \"Lengths of actual_lst, pred1_lst and pred2_lst do not match.\"\n",
    "            return (rt,msg)\n",
    "        # Check range of h\n",
    "        if (h >= len_act):\n",
    "            rt = -1\n",
    "            msg = \"The number of steps ahead is too large.\"\n",
    "            return (rt,msg)\n",
    "        # Check if criterion supported\n",
    "        if (crit != \"MSE\" and crit != \"MAPE\" and crit != \"MAD\" and crit != \"poly\"):\n",
    "            rt = -1\n",
    "            msg = \"The criterion is not supported.\"\n",
    "            return (rt,msg)  \n",
    "        # Check if every value of the input lists are numerical values\n",
    "        from re import compile as re_compile\n",
    "        comp = re_compile(\"^\\d+?\\.\\d+?$\")  \n",
    "        def compiled_regex(s):\n",
    "            \"\"\" Returns True is string is a number. \"\"\"\n",
    "            if comp.match(s) is None:\n",
    "                return s.isdigit()\n",
    "            return True\n",
    "        for actual, pred1, pred2 in zip(actual_lst, pred1_lst, pred2_lst):\n",
    "            is_actual_ok = compiled_regex(str(abs(actual)))\n",
    "            is_pred1_ok = compiled_regex(str(abs(pred1)))\n",
    "            is_pred2_ok = compiled_regex(str(abs(pred2)))\n",
    "            if (not (is_actual_ok and is_pred1_ok and is_pred2_ok)):  \n",
    "                msg = \"An element in the actual_lst, pred1_lst or pred2_lst is not numeric.\"\n",
    "                rt = -1\n",
    "                return (rt,msg)\n",
    "        return (rt,msg)\n",
    "    \n",
    "    # Error check\n",
    "    error_code = error_check()\n",
    "    # Raise error if cannot pass error check\n",
    "    if (error_code[0] == -1):\n",
    "        raise SyntaxError(error_code[1])\n",
    "        return\n",
    "    # Import libraries\n",
    "    from scipy.stats import t\n",
    "    import collections\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # Initialise lists\n",
    "    e1_lst = []\n",
    "    e2_lst = []\n",
    "    d_lst  = []\n",
    "    \n",
    "    # convert every value of the lists into real values\n",
    "    actual_lst = pd.Series(actual_lst).apply(lambda x: float(x)).tolist()\n",
    "    pred1_lst = pd.Series(pred1_lst).apply(lambda x: float(x)).tolist()\n",
    "    pred2_lst = pd.Series(pred2_lst).apply(lambda x: float(x)).tolist()\n",
    "    \n",
    "    # Length of lists (as real numbers)\n",
    "    T = float(len(actual_lst))\n",
    "    \n",
    "    # construct d according to crit\n",
    "    if (crit == \"MSE\"):\n",
    "        for actual,p1,p2 in zip(actual_lst,pred1_lst,pred2_lst):\n",
    "            e1_lst.append((actual - p1)**2)\n",
    "            e2_lst.append((actual - p2)**2)\n",
    "        for e1, e2 in zip(e1_lst, e2_lst):\n",
    "            d_lst.append(e1 - e2)\n",
    "    elif (crit == \"MAD\"):\n",
    "        for actual,p1,p2 in zip(actual_lst,pred1_lst,pred2_lst):\n",
    "            e1_lst.append(abs(actual - p1))\n",
    "            e2_lst.append(abs(actual - p2))\n",
    "        for e1, e2 in zip(e1_lst, e2_lst):\n",
    "            d_lst.append(e1 - e2)\n",
    "    elif (crit == \"MAPE\"):\n",
    "        for actual,p1,p2 in zip(actual_lst,pred1_lst,pred2_lst):\n",
    "            e1_lst.append(abs((actual - p1)/actual))\n",
    "            e2_lst.append(abs((actual - p2)/actual))\n",
    "        for e1, e2 in zip(e1_lst, e2_lst):\n",
    "            d_lst.append(e1 - e2)\n",
    "    elif (crit == \"poly\"):\n",
    "        for actual,p1,p2 in zip(actual_lst,pred1_lst,pred2_lst):\n",
    "            e1_lst.append(((actual - p1))**(power))\n",
    "            e2_lst.append(((actual - p2))**(power))\n",
    "        for e1, e2 in zip(e1_lst, e2_lst):\n",
    "            d_lst.append(e1 - e2)    \n",
    "    \n",
    "    # Mean of d        \n",
    "    mean_d = pd.Series(d_lst).mean()\n",
    "    \n",
    "    # Find autocovariance and construct DM test statistics\n",
    "    def autocovariance(Xi, N, k, Xs):\n",
    "        autoCov = 0\n",
    "        T = float(N)\n",
    "        for i in np.arange(0, N-k):\n",
    "              autoCov += ((Xi[i+k])-Xs)*(Xi[i]-Xs)\n",
    "        return (1/(T))*autoCov\n",
    "    gamma = []\n",
    "    for lag in range(0,h):\n",
    "        gamma.append(autocovariance(d_lst,len(d_lst),lag,mean_d)) # 0, 1, 2\n",
    "    V_d = (gamma[0] + 2*sum(gamma[1:]))/T\n",
    "    DM_stat=V_d**(-0.5)*mean_d\n",
    "    harvey_adj=((T+1-2*h+h*(h-1)/T)/T)**(0.5)\n",
    "    DM_stat = harvey_adj*DM_stat\n",
    "    # Find p-value\n",
    "    p_value = 2*t.cdf(-abs(DM_stat), df = T - 1)\n",
    "    \n",
    "    # Construct named tuple for return\n",
    "    dm_return = collections.namedtuple('dm_return', 'DM p_value')\n",
    "    \n",
    "    rt = dm_return(DM = DM_stat, p_value = p_value)\n",
    "    \n",
    "    return rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "advanced-recall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dm_return(DM=-6.931429070862556, p_value=1.2822988568989817e-11)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt = dm_test(temp2['footfall'], temp2['prediction'], temp['prediction'],h = 1, crit=\"MSE\")\n",
    "rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "jewish-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "register_matplotlib_converters()\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 22, 10\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "furnished-approval",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "laughing-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps = 1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)        \n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "biological-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['LSTM'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "interracial-violation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.2955 - val_loss: 0.3007\n",
      "Epoch 2/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.1271 - val_loss: 0.1721\n",
      "Epoch 3/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0780 - val_loss: 0.1035\n",
      "Epoch 4/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0590 - val_loss: 0.0844\n",
      "Epoch 5/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0478 - val_loss: 0.0671\n",
      "Epoch 6/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0408 - val_loss: 0.0556\n",
      "Epoch 7/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0354 - val_loss: 0.0405\n",
      "Epoch 8/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0305 - val_loss: 0.0318\n",
      "Epoch 9/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0277 - val_loss: 0.0299\n",
      "Epoch 10/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0263 - val_loss: 0.0266\n",
      "Epoch 11/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0240 - val_loss: 0.0279\n",
      "Epoch 12/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0238 - val_loss: 0.0270\n",
      "Epoch 13/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0221 - val_loss: 0.0250\n",
      "Epoch 14/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0221 - val_loss: 0.0270\n",
      "Epoch 15/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0214 - val_loss: 0.0267\n",
      "Epoch 16/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0203 - val_loss: 0.0260\n",
      "Epoch 17/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0207 - val_loss: 0.0254\n",
      "Epoch 18/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0196 - val_loss: 0.0249\n",
      "Epoch 19/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0194 - val_loss: 0.0248\n",
      "Epoch 20/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0191 - val_loss: 0.0261\n",
      "Epoch 21/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0193 - val_loss: 0.0262\n",
      "Epoch 22/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0189 - val_loss: 0.0245\n",
      "Epoch 23/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0184 - val_loss: 0.0216\n",
      "Epoch 24/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0187 - val_loss: 0.0224\n",
      "Epoch 25/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0183 - val_loss: 0.0217\n",
      "Epoch 26/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0177 - val_loss: 0.0211\n",
      "Epoch 27/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0175 - val_loss: 0.0194\n",
      "Epoch 28/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0172 - val_loss: 0.0209\n",
      "Epoch 29/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0172 - val_loss: 0.0189\n",
      "Epoch 30/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0170 - val_loss: 0.0232\n",
      "Epoch 1/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.2802 - val_loss: 0.2134\n",
      "Epoch 2/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.1012 - val_loss: 0.1048\n",
      "Epoch 3/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0666 - val_loss: 0.0986\n",
      "Epoch 4/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0540 - val_loss: 0.0759\n",
      "Epoch 5/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0435 - val_loss: 0.0669\n",
      "Epoch 6/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0360 - val_loss: 0.0592\n",
      "Epoch 7/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0302 - val_loss: 0.0458\n",
      "Epoch 8/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0263 - val_loss: 0.0433\n",
      "Epoch 9/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0253 - val_loss: 0.0389\n",
      "Epoch 10/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0239 - val_loss: 0.0348\n",
      "Epoch 11/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0231 - val_loss: 0.0375\n",
      "Epoch 12/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0218 - val_loss: 0.0336\n",
      "Epoch 13/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0213 - val_loss: 0.0326\n",
      "Epoch 14/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0201 - val_loss: 0.0325\n",
      "Epoch 15/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0199 - val_loss: 0.0291\n",
      "Epoch 16/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0198 - val_loss: 0.0283\n",
      "Epoch 17/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0192 - val_loss: 0.0285\n",
      "Epoch 18/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0189 - val_loss: 0.0283\n",
      "Epoch 19/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0181 - val_loss: 0.0281\n",
      "Epoch 20/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0179 - val_loss: 0.0254\n",
      "Epoch 21/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0177 - val_loss: 0.0252\n",
      "Epoch 22/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0176 - val_loss: 0.0263\n",
      "Epoch 23/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0172 - val_loss: 0.0283\n",
      "Epoch 24/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0171 - val_loss: 0.0257\n",
      "Epoch 25/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0168 - val_loss: 0.0263\n",
      "Epoch 26/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0170 - val_loss: 0.0254\n",
      "Epoch 27/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0164 - val_loss: 0.0268\n",
      "Epoch 28/30\n",
      "388/388 [==============================] - 5s 14ms/step - loss: 0.0166 - val_loss: 0.0248\n",
      "Epoch 29/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0162 - val_loss: 0.0276\n",
      "Epoch 30/30\n",
      "388/388 [==============================] - 5s 12ms/step - loss: 0.0162 - val_loss: 0.0274\n",
      "Epoch 1/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.3320 - val_loss: 0.2818\n",
      "Epoch 2/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.1369 - val_loss: 0.1370\n",
      "Epoch 3/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0954 - val_loss: 0.1225\n",
      "Epoch 4/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0783 - val_loss: 0.1047\n",
      "Epoch 5/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0652 - val_loss: 0.0900\n",
      "Epoch 6/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0586 - val_loss: 0.0802\n",
      "Epoch 7/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0531 - val_loss: 0.0691\n",
      "Epoch 8/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0468 - val_loss: 0.0606\n",
      "Epoch 9/30\n",
      "388/388 [==============================] - 5s 14ms/step - loss: 0.0448 - val_loss: 0.0601\n",
      "Epoch 10/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0423 - val_loss: 0.0582\n",
      "Epoch 11/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0411 - val_loss: 0.0552\n",
      "Epoch 12/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0399 - val_loss: 0.0518\n",
      "Epoch 13/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0386 - val_loss: 0.0523\n",
      "Epoch 14/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0379 - val_loss: 0.0541\n",
      "Epoch 15/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0368 - val_loss: 0.0486\n",
      "Epoch 16/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0355 - val_loss: 0.0476\n",
      "Epoch 17/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0356 - val_loss: 0.0457\n",
      "Epoch 18/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0348 - val_loss: 0.0455\n",
      "Epoch 19/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0343 - val_loss: 0.0451\n",
      "Epoch 20/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0347 - val_loss: 0.0441\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0340 - val_loss: 0.0466\n",
      "Epoch 22/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0327 - val_loss: 0.0442\n",
      "Epoch 23/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0323 - val_loss: 0.0473\n",
      "Epoch 24/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0320 - val_loss: 0.0434\n",
      "Epoch 25/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0309 - val_loss: 0.0425\n",
      "Epoch 26/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0303 - val_loss: 0.0404\n",
      "Epoch 27/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0302 - val_loss: 0.0427\n",
      "Epoch 28/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0303 - val_loss: 0.0418\n",
      "Epoch 29/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0292 - val_loss: 0.0442\n",
      "Epoch 30/30\n",
      "388/388 [==============================] - 5s 13ms/step - loss: 0.0294 - val_loss: 0.0419\n",
      "Epoch 1/30\n",
      "388/388 [==============================] - 6s 17ms/step - loss: 0.3145 - val_loss: 0.2916\n",
      "Epoch 2/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.1381 - val_loss: 0.1569\n",
      "Epoch 3/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0862 - val_loss: 0.0986\n",
      "Epoch 4/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0644 - val_loss: 0.0873\n",
      "Epoch 5/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0579 - val_loss: 0.0837\n",
      "Epoch 6/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0539 - val_loss: 0.0822\n",
      "Epoch 7/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0500 - val_loss: 0.0812\n",
      "Epoch 8/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0473 - val_loss: 0.0970\n",
      "Epoch 9/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0483 - val_loss: 0.0737\n",
      "Epoch 10/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0456 - val_loss: 0.0860\n",
      "Epoch 11/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0457 - val_loss: 0.0760\n",
      "Epoch 12/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0446 - val_loss: 0.0735\n",
      "Epoch 13/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0434 - val_loss: 0.0807\n",
      "Epoch 14/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0425 - val_loss: 0.0770\n",
      "Epoch 15/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0401 - val_loss: 0.0732\n",
      "Epoch 16/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0414 - val_loss: 0.0747\n",
      "Epoch 17/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0400 - val_loss: 0.0707\n",
      "Epoch 18/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0409 - val_loss: 0.0687\n",
      "Epoch 19/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0404 - val_loss: 0.0681\n",
      "Epoch 20/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0373 - val_loss: 0.0695\n",
      "Epoch 21/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0388 - val_loss: 0.0677\n",
      "Epoch 22/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0380 - val_loss: 0.0680\n",
      "Epoch 23/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0379 - val_loss: 0.0691\n",
      "Epoch 24/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0373 - val_loss: 0.0650\n",
      "Epoch 25/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0373 - val_loss: 0.0669\n",
      "Epoch 26/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0364 - val_loss: 0.0718\n",
      "Epoch 27/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0350 - val_loss: 0.0694\n",
      "Epoch 28/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0345 - val_loss: 0.0682\n",
      "Epoch 29/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0356 - val_loss: 0.0680\n",
      "Epoch 30/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0353 - val_loss: 0.0708\n",
      "Epoch 1/30\n",
      "388/388 [==============================] - 6s 17ms/step - loss: 0.3284 - val_loss: 0.2035\n",
      "Epoch 2/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.1168 - val_loss: 0.1223\n",
      "Epoch 3/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0747 - val_loss: 0.0896\n",
      "Epoch 4/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0553 - val_loss: 0.0782\n",
      "Epoch 5/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0481 - val_loss: 0.0688\n",
      "Epoch 6/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0413 - val_loss: 0.0605\n",
      "Epoch 7/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0370 - val_loss: 0.0490\n",
      "Epoch 8/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0320 - val_loss: 0.0429\n",
      "Epoch 9/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0292 - val_loss: 0.0362\n",
      "Epoch 10/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0277 - val_loss: 0.0359\n",
      "Epoch 11/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0245 - val_loss: 0.0334\n",
      "Epoch 12/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0240 - val_loss: 0.0313\n",
      "Epoch 13/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0227 - val_loss: 0.0301\n",
      "Epoch 14/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0213 - val_loss: 0.0291\n",
      "Epoch 15/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0216 - val_loss: 0.0285\n",
      "Epoch 16/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0205 - val_loss: 0.0273\n",
      "Epoch 17/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0193 - val_loss: 0.0264\n",
      "Epoch 18/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0190 - val_loss: 0.0269\n",
      "Epoch 19/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0187 - val_loss: 0.0248\n",
      "Epoch 20/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0185 - val_loss: 0.0243\n",
      "Epoch 21/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0178 - val_loss: 0.0222\n",
      "Epoch 22/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0175 - val_loss: 0.0242\n",
      "Epoch 23/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0169 - val_loss: 0.0245\n",
      "Epoch 24/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0167 - val_loss: 0.0214\n",
      "Epoch 25/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0165 - val_loss: 0.0216\n",
      "Epoch 26/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0167 - val_loss: 0.0227\n",
      "Epoch 27/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0161 - val_loss: 0.0204\n",
      "Epoch 28/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0159 - val_loss: 0.0207\n",
      "Epoch 29/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0159 - val_loss: 0.0203\n",
      "Epoch 30/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0155 - val_loss: 0.0218\n",
      "Epoch 1/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.2715 - val_loss: 0.3393\n",
      "Epoch 2/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.1166 - val_loss: 0.2059\n",
      "Epoch 3/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0782 - val_loss: 0.1198\n",
      "Epoch 4/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0595 - val_loss: 0.0913\n",
      "Epoch 5/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0469 - val_loss: 0.0711\n",
      "Epoch 6/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0396 - val_loss: 0.0488\n",
      "Epoch 7/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0338 - val_loss: 0.0390\n",
      "Epoch 8/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0302 - val_loss: 0.0340\n",
      "Epoch 9/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0260 - val_loss: 0.0291\n",
      "Epoch 10/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0237 - val_loss: 0.0255\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0217 - val_loss: 0.0252\n",
      "Epoch 12/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0215 - val_loss: 0.0255\n",
      "Epoch 13/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0194 - val_loss: 0.0223\n",
      "Epoch 14/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0203 - val_loss: 0.0228\n",
      "Epoch 15/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0192 - val_loss: 0.0213\n",
      "Epoch 16/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0182 - val_loss: 0.0200\n",
      "Epoch 17/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0181 - val_loss: 0.0194\n",
      "Epoch 18/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0185 - val_loss: 0.0202\n",
      "Epoch 19/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0174 - val_loss: 0.0200\n",
      "Epoch 20/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0171 - val_loss: 0.0221\n",
      "Epoch 21/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0173 - val_loss: 0.0203\n",
      "Epoch 22/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0174 - val_loss: 0.0212\n",
      "Epoch 23/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0165 - val_loss: 0.0186\n",
      "Epoch 24/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0163 - val_loss: 0.0208\n",
      "Epoch 25/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0164 - val_loss: 0.0206\n",
      "Epoch 26/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0165 - val_loss: 0.0196\n",
      "Epoch 27/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0155 - val_loss: 0.0181\n",
      "Epoch 28/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0158 - val_loss: 0.0181\n",
      "Epoch 29/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.0155 - val_loss: 0.0191\n",
      "Epoch 30/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0154 - val_loss: 0.0164\n",
      "Epoch 1/30\n",
      "388/388 [==============================] - 6s 17ms/step - loss: 0.2616 - val_loss: 0.1378\n",
      "Epoch 2/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.1155 - val_loss: 0.1026\n",
      "Epoch 3/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0756 - val_loss: 0.0718\n",
      "Epoch 4/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0606 - val_loss: 0.0618\n",
      "Epoch 5/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0491 - val_loss: 0.0613\n",
      "Epoch 6/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0447 - val_loss: 0.0505\n",
      "Epoch 7/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0394 - val_loss: 0.0579\n",
      "Epoch 8/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0364 - val_loss: 0.0449\n",
      "Epoch 9/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0348 - val_loss: 0.0457\n",
      "Epoch 10/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0325 - val_loss: 0.0446\n",
      "Epoch 11/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0314 - val_loss: 0.0435\n",
      "Epoch 12/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0298 - val_loss: 0.0456\n",
      "Epoch 13/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0298 - val_loss: 0.0453\n",
      "Epoch 14/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0292 - val_loss: 0.0466\n",
      "Epoch 15/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0279 - val_loss: 0.0461\n",
      "Epoch 16/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0282 - val_loss: 0.0472\n",
      "Epoch 17/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0283 - val_loss: 0.0490\n",
      "Epoch 18/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0281 - val_loss: 0.0496\n",
      "Epoch 19/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0270 - val_loss: 0.0500\n",
      "Epoch 20/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0274 - val_loss: 0.0468\n",
      "Epoch 21/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0271 - val_loss: 0.0477\n",
      "Epoch 22/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0274 - val_loss: 0.0484\n",
      "Epoch 23/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0260 - val_loss: 0.0509\n",
      "Epoch 24/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0255 - val_loss: 0.0548\n",
      "Epoch 25/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0258 - val_loss: 0.0503\n",
      "Epoch 26/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0254 - val_loss: 0.0471\n",
      "Epoch 27/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0251 - val_loss: 0.0470\n",
      "Epoch 28/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0250 - val_loss: 0.0463\n",
      "Epoch 29/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0246 - val_loss: 0.0500\n",
      "Epoch 30/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0245 - val_loss: 0.0496\n",
      "Epoch 1/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.3152 - val_loss: 0.1880\n",
      "Epoch 2/30\n",
      "388/388 [==============================] - 6s 14ms/step - loss: 0.1649 - val_loss: 0.1492\n",
      "Epoch 3/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.1245 - val_loss: 0.1224\n",
      "Epoch 4/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.1123 - val_loss: 0.1070\n",
      "Epoch 5/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.1036 - val_loss: 0.0858\n",
      "Epoch 6/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0968 - val_loss: 0.0817\n",
      "Epoch 7/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0887 - val_loss: 0.0781\n",
      "Epoch 8/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0888 - val_loss: 0.0756\n",
      "Epoch 9/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0846 - val_loss: 0.0705\n",
      "Epoch 10/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0824 - val_loss: 0.0673\n",
      "Epoch 11/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0788 - val_loss: 0.0665\n",
      "Epoch 12/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0788 - val_loss: 0.0658\n",
      "Epoch 13/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0747 - val_loss: 0.0612\n",
      "Epoch 14/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0747 - val_loss: 0.0653\n",
      "Epoch 15/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0736 - val_loss: 0.0691\n",
      "Epoch 16/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0721 - val_loss: 0.0744\n",
      "Epoch 17/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0712 - val_loss: 0.0683\n",
      "Epoch 18/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0710 - val_loss: 0.0674\n",
      "Epoch 19/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0706 - val_loss: 0.0677\n",
      "Epoch 20/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0705 - val_loss: 0.0707\n",
      "Epoch 21/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0684 - val_loss: 0.0702\n",
      "Epoch 22/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0658 - val_loss: 0.0671\n",
      "Epoch 23/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0680 - val_loss: 0.0697\n",
      "Epoch 24/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0665 - val_loss: 0.0638\n",
      "Epoch 25/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0664 - val_loss: 0.0717\n",
      "Epoch 26/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0650 - val_loss: 0.0706\n",
      "Epoch 27/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0694 - val_loss: 0.0700\n",
      "Epoch 28/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0660 - val_loss: 0.0687\n",
      "Epoch 29/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0620 - val_loss: 0.0681\n",
      "Epoch 30/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0629 - val_loss: 0.0598\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 6s 17ms/step - loss: 0.3908 - val_loss: 0.1361\n",
      "Epoch 2/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.1535 - val_loss: 0.1061\n",
      "Epoch 3/30\n",
      "388/388 [==============================] - 7s 18ms/step - loss: 0.1105 - val_loss: 0.0884\n",
      "Epoch 4/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0968 - val_loss: 0.0886\n",
      "Epoch 5/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0834 - val_loss: 0.0762\n",
      "Epoch 6/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0776 - val_loss: 0.0726\n",
      "Epoch 7/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0699 - val_loss: 0.0707\n",
      "Epoch 8/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0658 - val_loss: 0.0682\n",
      "Epoch 9/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0618 - val_loss: 0.0574\n",
      "Epoch 10/30\n",
      "388/388 [==============================] - 7s 19ms/step - loss: 0.0574 - val_loss: 0.0530\n",
      "Epoch 11/30\n",
      "388/388 [==============================] - 7s 17ms/step - loss: 0.0562 - val_loss: 0.0569\n",
      "Epoch 12/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0546 - val_loss: 0.0614\n",
      "Epoch 13/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0506 - val_loss: 0.0494\n",
      "Epoch 14/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0491 - val_loss: 0.0512\n",
      "Epoch 15/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0488 - val_loss: 0.0510\n",
      "Epoch 16/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0478 - val_loss: 0.0492\n",
      "Epoch 17/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0469 - val_loss: 0.0497\n",
      "Epoch 18/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0479 - val_loss: 0.0505\n",
      "Epoch 19/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0460 - val_loss: 0.0468\n",
      "Epoch 20/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0460 - val_loss: 0.0475\n",
      "Epoch 21/30\n",
      "388/388 [==============================] - 7s 17ms/step - loss: 0.0453 - val_loss: 0.0470\n",
      "Epoch 22/30\n",
      "388/388 [==============================] - 8s 20ms/step - loss: 0.0444 - val_loss: 0.0435\n",
      "Epoch 23/30\n",
      "388/388 [==============================] - 7s 18ms/step - loss: 0.0456 - val_loss: 0.0477\n",
      "Epoch 24/30\n",
      "388/388 [==============================] - 7s 17ms/step - loss: 0.0446 - val_loss: 0.0567\n",
      "Epoch 25/30\n",
      "388/388 [==============================] - 8s 22ms/step - loss: 0.0434 - val_loss: 0.0468\n",
      "Epoch 26/30\n",
      "388/388 [==============================] - 8s 20ms/step - loss: 0.0426 - val_loss: 0.0447\n",
      "Epoch 27/30\n",
      "388/388 [==============================] - 7s 18ms/step - loss: 0.0425 - val_loss: 0.0459\n",
      "Epoch 28/30\n",
      "388/388 [==============================] - 8s 19ms/step - loss: 0.0419 - val_loss: 0.0475\n",
      "Epoch 29/30\n",
      "388/388 [==============================] - 7s 19ms/step - loss: 0.0415 - val_loss: 0.0451\n",
      "Epoch 30/30\n",
      "388/388 [==============================] - 7s 19ms/step - loss: 0.0414 - val_loss: 0.0457\n",
      "Epoch 1/30\n",
      "388/388 [==============================] - 8s 20ms/step - loss: 0.3521 - val_loss: 0.2105\n",
      "Epoch 2/30\n",
      "388/388 [==============================] - 7s 17ms/step - loss: 0.1485 - val_loss: 0.1155\n",
      "Epoch 3/30\n",
      "388/388 [==============================] - 7s 19ms/step - loss: 0.1191 - val_loss: 0.0795\n",
      "Epoch 4/30\n",
      "388/388 [==============================] - 7s 18ms/step - loss: 0.1012 - val_loss: 0.0681\n",
      "Epoch 5/30\n",
      "388/388 [==============================] - 7s 18ms/step - loss: 0.0873 - val_loss: 0.0626\n",
      "Epoch 6/30\n",
      "388/388 [==============================] - 7s 18ms/step - loss: 0.0756 - val_loss: 0.0563\n",
      "Epoch 7/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0670 - val_loss: 0.0523\n",
      "Epoch 8/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0565 - val_loss: 0.0497\n",
      "Epoch 9/30\n",
      "388/388 [==============================] - 7s 18ms/step - loss: 0.0593 - val_loss: 0.0531\n",
      "Epoch 10/30\n",
      "388/388 [==============================] - 7s 18ms/step - loss: 0.0540 - val_loss: 0.0516\n",
      "Epoch 11/30\n",
      "388/388 [==============================] - 6s 17ms/step - loss: 0.0509 - val_loss: 0.0534\n",
      "Epoch 12/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0502 - val_loss: 0.0543\n",
      "Epoch 13/30\n",
      "388/388 [==============================] - 7s 17ms/step - loss: 0.0490 - val_loss: 0.0553\n",
      "Epoch 14/30\n",
      "388/388 [==============================] - 7s 18ms/step - loss: 0.0486 - val_loss: 0.0502\n",
      "Epoch 15/30\n",
      "388/388 [==============================] - 8s 20ms/step - loss: 0.0457 - val_loss: 0.0497\n",
      "Epoch 16/30\n",
      "388/388 [==============================] - 7s 19ms/step - loss: 0.0458 - val_loss: 0.0531\n",
      "Epoch 17/30\n",
      "388/388 [==============================] - 6s 17ms/step - loss: 0.0476 - val_loss: 0.0523\n",
      "Epoch 18/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0494 - val_loss: 0.0534\n",
      "Epoch 19/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0486 - val_loss: 0.0530\n",
      "Epoch 20/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0458 - val_loss: 0.0530\n",
      "Epoch 21/30\n",
      "388/388 [==============================] - 7s 18ms/step - loss: 0.0453 - val_loss: 0.0525\n",
      "Epoch 22/30\n",
      "388/388 [==============================] - 6s 15ms/step - loss: 0.0445 - val_loss: 0.0503\n",
      "Epoch 23/30\n",
      "388/388 [==============================] - 6s 17ms/step - loss: 0.0443 - val_loss: 0.0505\n",
      "Epoch 24/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0440 - val_loss: 0.0505\n",
      "Epoch 25/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0422 - val_loss: 0.0512\n",
      "Epoch 26/30\n",
      "388/388 [==============================] - 6s 17ms/step - loss: 0.0430 - val_loss: 0.0508\n",
      "Epoch 27/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0432 - val_loss: 0.0511\n",
      "Epoch 28/30\n",
      "388/388 [==============================] - 7s 18ms/step - loss: 0.0444 - val_loss: 0.0479\n",
      "Epoch 29/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0431 - val_loss: 0.0539\n",
      "Epoch 30/30\n",
      "388/388 [==============================] - 6s 16ms/step - loss: 0.0422 - val_loss: 0.0528\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for loc in ff.location.unique()[0:10]:\n",
    "    \n",
    "    ff_loc = ff.loc[(ff.location <= loc) & (ff.location >= loc)][[\n",
    "            'timestamp','footfall','year','month','day','hour','day_of_week']]    \n",
    "    ff_loc.index = ff_loc.timestamp\n",
    "    ff_loc = ff_loc.resample('H').mean()\n",
    "\n",
    "    ff_loc['footfall'].replace(0, np.nan, inplace = True)\n",
    "    ff_loc['footfall'] = ff_loc['footfall'].interpolate(method='linear')\n",
    "    ff_loc = ff_loc.reset_index(level = ['timestamp'])\n",
    "    ff_loc.timestamp = pd.to_datetime(ff_loc.timestamp, format = '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    temp = ff_loc[['timestamp', 'footfall']]\n",
    "    temp.index = temp.timestamp\n",
    "    temp['year'] = temp.timestamp.dt.year\n",
    "    temp['month'] = temp.timestamp.dt.month\n",
    "    temp['day'] = temp.timestamp.dt.day\n",
    "    temp['hour'] = temp.timestamp.dt.hour\n",
    "    temp['day_of_week'] = temp.timestamp.dt.dayofweek + 1\n",
    "\n",
    "    train = temp.loc[(temp.timestamp >= '2018-01-01 00:00') & (temp.timestamp <= '2019-07-28 23:00')][[\n",
    "        'footfall','month','day','hour','day_of_week']]\n",
    "    test = temp.loc[(temp.timestamp >= '2019-07-29 00:00') & (temp.timestamp <= '2019-08-18 23:00')][[\n",
    "        'footfall','month','day','hour','day_of_week']]  \n",
    "    \n",
    "    ff_transformer = RobustScaler()\n",
    "    ff_transformer = ff_transformer.fit(train[['footfall']])\n",
    "\n",
    "    train['footfall'] = ff_transformer.transform(train[['footfall']])\n",
    "    test['footfall'] = ff_transformer.transform(test[['footfall']])\n",
    "    \n",
    "    time_steps = 10\n",
    "    X_train, y_train = create_dataset(train, train.footfall, time_steps)\n",
    "    X_test, y_test = create_dataset(test, test.footfall, time_steps)\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(\n",
    "      keras.layers.Bidirectional(\n",
    "        keras.layers.LSTM(\n",
    "          units=128, \n",
    "          input_shape=(X_train.shape[1], X_train.shape[2])\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    model.add(keras.layers.Dropout(rate=0.2))\n",
    "    model.add(keras.layers.Dense(units=1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')    \n",
    "    \n",
    "    history = model.fit(\n",
    "    X_train, y_train, \n",
    "    epochs=30, \n",
    "    batch_size=32, \n",
    "    validation_split=0.1,\n",
    "    shuffle=False\n",
    "    )\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_train_inv = ff_transformer.inverse_transform(y_train.reshape(1, -1))\n",
    "    y_test_inv = ff_transformer.inverse_transform(y_test.reshape(1, -1))\n",
    "    y_pred_inv = ff_transformer.inverse_transform(y_pred)\n",
    "    \n",
    "    lstm_rmse = rmse(y_test_inv.flatten(), y_pred_inv.flatten())\n",
    "    \n",
    "    result['LSTM'][j] = lstm_rmse\n",
    "    \n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "built-korea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>Naive</th>\n",
       "      <th>Moving_Average12</th>\n",
       "      <th>Moving_Average24</th>\n",
       "      <th>Moving_Average30</th>\n",
       "      <th>Expoential_Smoothing</th>\n",
       "      <th>SARIMA</th>\n",
       "      <th>LSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>660.733618</td>\n",
       "      <td>438.124377</td>\n",
       "      <td>380.697612</td>\n",
       "      <td>435.824077</td>\n",
       "      <td>423.488557</td>\n",
       "      <td>417.842803</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>520.571453</td>\n",
       "      <td>450.796608</td>\n",
       "      <td>327.748727</td>\n",
       "      <td>371.546914</td>\n",
       "      <td>396.486996</td>\n",
       "      <td>350.549984</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>277.951764</td>\n",
       "      <td>216.414675</td>\n",
       "      <td>190.836343</td>\n",
       "      <td>208.629228</td>\n",
       "      <td>209.257630</td>\n",
       "      <td>208.223988</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.0</td>\n",
       "      <td>511.515018</td>\n",
       "      <td>377.816876</td>\n",
       "      <td>392.249377</td>\n",
       "      <td>440.817514</td>\n",
       "      <td>328.671785</td>\n",
       "      <td>315.860758</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.0</td>\n",
       "      <td>321.298819</td>\n",
       "      <td>226.211294</td>\n",
       "      <td>214.664716</td>\n",
       "      <td>248.059289</td>\n",
       "      <td>245.561794</td>\n",
       "      <td>233.264410</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>78.0</td>\n",
       "      <td>686.925250</td>\n",
       "      <td>488.953839</td>\n",
       "      <td>378.221677</td>\n",
       "      <td>440.177805</td>\n",
       "      <td>416.956271</td>\n",
       "      <td>425.775341</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>87.0</td>\n",
       "      <td>280.699218</td>\n",
       "      <td>222.816230</td>\n",
       "      <td>208.413313</td>\n",
       "      <td>209.433377</td>\n",
       "      <td>193.382826</td>\n",
       "      <td>198.950650</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>88.0</td>\n",
       "      <td>181.602965</td>\n",
       "      <td>175.427137</td>\n",
       "      <td>143.093646</td>\n",
       "      <td>142.725657</td>\n",
       "      <td>177.919970</td>\n",
       "      <td>155.171088</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>89.0</td>\n",
       "      <td>170.063667</td>\n",
       "      <td>225.046256</td>\n",
       "      <td>204.175617</td>\n",
       "      <td>211.756172</td>\n",
       "      <td>207.826243</td>\n",
       "      <td>205.387776</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>91.0</td>\n",
       "      <td>202.499036</td>\n",
       "      <td>159.444603</td>\n",
       "      <td>139.627218</td>\n",
       "      <td>143.965067</td>\n",
       "      <td>179.807262</td>\n",
       "      <td>142.644924</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location       Naive  Moving_Average12  Moving_Average24  Moving_Average30  \\\n",
       "0       5.0  660.733618        438.124377        380.697612        435.824077   \n",
       "1       6.0  520.571453        450.796608        327.748727        371.546914   \n",
       "2       7.0  277.951764        216.414675        190.836343        208.629228   \n",
       "3      31.0  511.515018        377.816876        392.249377        440.817514   \n",
       "4      62.0  321.298819        226.211294        214.664716        248.059289   \n",
       "5      78.0  686.925250        488.953839        378.221677        440.177805   \n",
       "6      87.0  280.699218        222.816230        208.413313        209.433377   \n",
       "7      88.0  181.602965        175.427137        143.093646        142.725657   \n",
       "8      89.0  170.063667        225.046256        204.175617        211.756172   \n",
       "9      91.0  202.499036        159.444603        139.627218        143.965067   \n",
       "\n",
       "   Expoential_Smoothing      SARIMA  LSTM  \n",
       "0            423.488557  417.842803   292  \n",
       "1            396.486996  350.549984   243  \n",
       "2            209.257630  208.223988   163  \n",
       "3            328.671785  315.860758   245  \n",
       "4            245.561794  233.264410   168  \n",
       "5            416.956271  425.775341   265  \n",
       "6            193.382826  198.950650   129  \n",
       "7            177.919970  155.171088    95  \n",
       "8            207.826243  205.387776   152  \n",
       "9            179.807262  142.644924   122  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "suspended-amplifier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dm_return(DM=-2.525360531691746, p_value=0.011870345175512652)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt = dm_test(y_test_inv.flatten(), y_pred_inv.flatten(), temp2['prediction'][10:],h = 1, crit=\"MSE\")\n",
    "rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-reduction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbsim",
   "language": "python",
   "name": "urbsim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
